{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ros/Documents/kaggleData/data'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../../../kaggleData/data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "lable = pd.read_csv(\"labels.csv\")\n",
    "test = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109237\n",
      "1103\n",
      "7443\n"
     ]
    }
   ],
   "source": [
    "lable_length = len(lable)import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn import preprocessing \n",
    "train_length = len(train)\n",
    "test_length = len(test)\n",
    "print(train_length)\n",
    "print(lable_length)\n",
    "print(test_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 'culture::abruzzi'],\n",
       "       [1, 'culture::achaemenid'],\n",
       "       [2, 'culture::aegean'],\n",
       "       ...,\n",
       "       [1100, 'tag::zeus'],\n",
       "       [1101, 'tag::zigzag pattern'],\n",
       "       [1102, 'tag::zodiac']], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['10023b2cc4ed5f68', '0 1 2'],\n",
       "       ['100fbe75ed8fd887', '0 1 2'],\n",
       "       ['101b627524a04f19', '0 1 2'],\n",
       "       ...,\n",
       "       ['ffe54b454396d97c', '0 1 2'],\n",
       "       ['ffe7d7db4e4aa37f', '0 1 2'],\n",
       "       ['ffed0a4aca0d5457', '0 1 2']], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                     id attribute_ids\n",
       "0     10023b2cc4ed5f68         0 1 2\n",
       "1     100fbe75ed8fd887         0 1 2\n",
       "2     101b627524a04f19         0 1 2\n",
       "3     10234480c41284c6         0 1 2\n",
       "4     1023b0e2636dcea8         0 1 2\n",
       "5      1039cd6cf85845c         0 1 2\n",
       "6      103a5b3f83fbe88         0 1 2\n",
       "7     10413aaae8d6a9a2         0 1 2\n",
       "8     10423822b93a65ab         0 1 2\n",
       "9     1052bf702cb099f7         0 1 2\n",
       "10     10543c918a43a8d         0 1 2\n",
       "11    105c9a3453da79c3         0 1 2\n",
       "12    1060688bbf6eac87         0 1 2\n",
       "13    106a247caeabd15a         0 1 2\n",
       "14    106e21606add59f3         0 1 2\n",
       "15    107c38495881b6c9         0 1 2\n",
       "16    108815dd3752ab64         0 1 2\n",
       "17    10943defdd5d5e89         0 1 2\n",
       "18    10a39a78c44ef27c         0 1 2\n",
       "19     10ab70df067bdb4         0 1 2\n",
       "20    10b28e3de3566582         0 1 2\n",
       "21    10b32964331a6cc3         0 1 2\n",
       "22    10b4562e7fa6f668         0 1 2\n",
       "23    10db1c338e1d822f         0 1 2\n",
       "24    10e0c215f5f3084e         0 1 2\n",
       "25    10e95bead8e0b35b         0 1 2\n",
       "26    1100d7b0f24fee88         0 1 2\n",
       "27    11099b321e8c7066         0 1 2\n",
       "28    110df388fd5c50e4         0 1 2\n",
       "29    113520ea0138f76d         0 1 2\n",
       "...                ...           ...\n",
       "7413  ff2da1f0ed3e3ebe         0 1 2\n",
       "7414  ff3a9fa43f8eab9c         0 1 2\n",
       "7415  ff44490e20740a19         0 1 2\n",
       "7416  ff481bb029678d5d         0 1 2\n",
       "7417  ff4c3570fb7b90d3         0 1 2\n",
       "7418  ff4f548d08414709         0 1 2\n",
       "7419  ff668377a518ea5f         0 1 2\n",
       "7420  ff6a549b2d7a0e76         0 1 2\n",
       "7421  ff6ee1b37c8dc1ae         0 1 2\n",
       "7422  ff85460d6b853b49         0 1 2\n",
       "7423   ff8721b85d1b5a5         0 1 2\n",
       "7424  ff8bef7d0de52b31         0 1 2\n",
       "7425  ff92504c82c41e0f         0 1 2\n",
       "7426  ff9d4b77c124c9f2         0 1 2\n",
       "7427  ff9ddf70cb1c2674         0 1 2\n",
       "7428  ffaf8c3fe0b1d9b6         0 1 2\n",
       "7429  ffb61df4a6734772         0 1 2\n",
       "7430  ffb73f95b8721900         0 1 2\n",
       "7431  ffb937b55755323e         0 1 2\n",
       "7432  ffbcf8b91a8e8ce0         0 1 2\n",
       "7433  ffbf4849bde21b0a         0 1 2\n",
       "7434  ffc96e053345419d         0 1 2\n",
       "7435  ffcb16053099d795         0 1 2\n",
       "7436  ffcf745289465074         0 1 2\n",
       "7437  ffd1372fe67e65f0         0 1 2\n",
       "7438  ffd79eadf642221b         0 1 2\n",
       "7439  ffd96986aa333f4d         0 1 2\n",
       "7440  ffe54b454396d97c         0 1 2\n",
       "7441  ffe7d7db4e4aa37f         0 1 2\n",
       "7442  ffed0a4aca0d5457         0 1 2\n",
       "\n",
       "[7443 rows x 2 columns]>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1000483014d91860', '147 616 813'],\n",
       "       ['1000fe2e667721fe', '51 616 734 813'],\n",
       "       ['1001614cb89646ee', '776'],\n",
       "       ...,\n",
       "       ['ffff3e66a42ab868', '156 763'],\n",
       "       ['ffff45b237a32bd5', '121 433'],\n",
       "       ['ffffbf00586b8e37', '462 733 813 1020']], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatData(train,lable_length):\n",
    "    train = np.array(train)\n",
    "    train_data = []\n",
    "    for t in range(train_length):\n",
    "        v = np.zeros(lable_length)-1\n",
    "        #print(train[t,1])\n",
    "        for s in train[t,1].split(\" \"):\n",
    "            #print(s)\n",
    "            v[int(s)] = 1\n",
    "        train_data.append([train[t,0],v])\n",
    "    return np.array(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1000483014d91860' array([-1., -1., -1., ..., -1., -1., -1.])]\n",
      " ['1000fe2e667721fe' array([-1., -1., -1., ..., -1., -1., -1.])]\n",
      " ['1001614cb89646ee' array([-1., -1., -1., ..., -1., -1., -1.])]\n",
      " ...\n",
      " ['ffff3e66a42ab868' array([-1., -1., -1., ..., -1., -1., -1.])]\n",
      " ['ffff45b237a32bd5' array([-1., -1., -1., ..., -1., -1., -1.])]\n",
      " ['ffffbf00586b8e37' array([-1., -1., -1., ..., -1., -1., -1.])]]\n"
     ]
    }
   ],
   "source": [
    "train_lib = creatData(train,lable_length)\n",
    "print(train_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.transforms' has no attribute 'Resize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-5834bdff0d2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_transformer = transforms.Compose([\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0;31m# resize the image to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;31m#transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   transforms.ToTensor()])             # transform it into a PyTorch Tensor\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.transforms' has no attribute 'Resize'"
     ]
    }
   ],
   "source": [
    "train_transformer = transforms.Compose([\n",
    "  transforms.Resize((128,128)),              # resize the image to \n",
    "  #transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
    "  transforms.ToTensor()])             # transform it into a PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainDataset(Dataset):\n",
    "    def __init__(self, train_lib, transform=None):\n",
    "        self.filenames = train_lib[:,0]\n",
    "        self.labels = train_lib[:,1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(\"train/\"+format(self.filenames[idx])+'.png')  # PIL image\n",
    "        image = self.transform(image)\n",
    "        return image, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    def __init__(self, test_lib, transform=None):\n",
    "        test_lib = np.array(test_lib)\n",
    "        self.filenames = test_lib[:,0]\n",
    "        #self.labels = test_lib[:,1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(\"test/\"+format(self.filenames[idx])+'.png')  # PIL image\n",
    "        image = self.transform(image)\n",
    "        return image,self.filenames[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(trainDataset(train_lib, train_transformer), \n",
    "                              batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(testDataset(test, train_transformer),batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_dataloader.dataset[0][1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(train_dataloader.dataset[4][0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = models.resnet18(pretrained=False) \n",
    "resnet_model.fc= nn.Linear(in_features=512, out_features=lable_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = resnet_model\n",
    "cnn.cuda()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for step, (x, y) in enumerate(train_dataloader):\n",
    "        data = Variable(x).cuda()   # batch x\n",
    "        target = Variable(y).cuda()   # batch y\n",
    "        #print(data.type())\n",
    "        #print(target.type())\n",
    "        output = cnn(data)               # cnn output\n",
    "        #loss = nn.functional.nll_loss(output, target)\n",
    "        loss = loss_func(output, target.float())   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        if step==0:\n",
    "            start = time.time()\n",
    "            ti = 0\n",
    "        elif step==100:\n",
    "            ti = time.time()-start #total time = ti*(length/100)\n",
    "            #print(ti)\n",
    "            ti = ti*(len(train_dataloader)/100)\n",
    "        if step % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime Remain : {} '.format(epoch, \n",
    "                                                                            step * len(data), \n",
    "                                                                            len(train_dataloader.dataset),\n",
    "                                                                            100.*step/len(train_dataloader), \n",
    "                                                                            loss.data.item(),\n",
    "                                                                            datetime.timedelta(seconds=(ti*(((len(train_dataloader)-step)/len(train_dataloader)))))))\n",
    "            #print('    Time Remain : {}'.format(datetime.timedelta(seconds=(ti*(((length-i)/length))))))\n",
    "    print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(4):\n",
    "    optimizer = torch.optim.SGD(cnn.parameters(), lr=0.001/(2**epoch),momentum=0.9)\n",
    "    #optimizer = torch.optim.ASGD(cnn.parameters(), lr=0.001)\n",
    "    #optimizer = torch.optim.Adam(cnn.parameters(), lr=0.0001/(2**epoch))\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    #loss_func = torch.nn.MultiLabelMarginLoss()\n",
    "    #loss_func = torch.nn.SmoothL1Loss()\n",
    "    #loss_func = FocalLoss(class_num = lable_length)\n",
    "    #optimizer = torch.optim.ASGD(cnn.parameters(), lr=0.0005/(epoch+1))\n",
    "    train(epoch)\n",
    "    if epoch==0:\n",
    "        torch.save(cnn, '/home/ros/Documents/net_E0.pkl')\n",
    "    elif epoch==1:\n",
    "        torch.save(cnn, '/home/ros/Documents/net_E1.pkl')\n",
    "    elif epoch==2:\n",
    "        torch.save(cnn, '/home/ros/Documents/net_E2.pkl')\n",
    "    elif epoch==3:\n",
    "        torch.save(cnn, '/home/ros/Documents/net_E3.pkl')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn, '/home/ros/Documents/net.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFromT(model):\n",
    "    model = model.eval()\n",
    "    #model = model.cpu().eval()\n",
    "    ans = []\n",
    "    for step, (x, y) in enumerate(train_dataloader):\n",
    "        data = Variable(x).cuda()\n",
    "        #data = Variable(x)\n",
    "        target = np.array(y)\n",
    "        output = model(data)\n",
    "        v = output.cpu().detach()\n",
    "        v = torch.sigmoid(v)\n",
    "        #avg=torch.max(v,dim=1,keepdim=True)\n",
    "        #print(len(v))\n",
    "        #for i in range(len(v)):\n",
    "            #v[i] = 1*(v[i]/avg[i])\n",
    "            #v[i] = v[i]**2\n",
    "        #vp = preprocessing.minmax_scale(v, feature_range=(-1,1),axis=1)\n",
    "        vp = torch.sigmoid(v)\n",
    "        v = np.array(v)\n",
    "        vp = np.array(vp)\n",
    "        if step==0:\n",
    "            break\n",
    "        #print(v)\n",
    "        #v = preprocessing.minmax_scale(v, feature_range=(0,1),axis=1)\n",
    "        #v = min_max_scaler.fit_transform(v)\n",
    "#         v = torch.from_numpy(v)\n",
    "#         v = F.softmax(v, dim=0)\n",
    "#         v = np.array(v)\n",
    "        #v = sigmoid(v)\n",
    "        #print(\"==========\")\n",
    "        #print(np.max(v[0]))\n",
    "        #print(np.min(v[0]))\n",
    "        #print(\"==========\")\n",
    "    print(\"Finish\")\n",
    "    return v[0],vp[0],target[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v,vp,t = testFromT(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(v[100:800], '-')\n",
    "plt.plot(t[100:800], '--');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPre(output):\n",
    "    a = ''\n",
    "    output = np.array(output)\n",
    "    #output = np.where(output > 0.8,1,0)\n",
    "    for i in range(len(output)):\n",
    "        if output[i]>80:\n",
    "            a = a + format(i)+' '\n",
    "    #print(a)\n",
    "    return a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model = model.eval()\n",
    "    ans = []\n",
    "    for step, (x, y) in enumerate(test_dataloader):\n",
    "        data = Variable(x).cuda()\n",
    "        target = y\n",
    "        output = model(data)\n",
    "        v = output.cpu().detach()\n",
    "        \n",
    "        v = np.array(v)\n",
    "        v = preprocessing.minmax_scale(v, feature_range=(-100,100))\n",
    "        #v = min_max_scaler.fit_transform(v)\n",
    "#         v = torch.from_numpy(v)\n",
    "#         v = F.softmax(v, dim=0)\n",
    "#         v = np.array(v)\n",
    "        #v = sigmoid(v)\n",
    "        #print(np.max(v[0]))\n",
    "        #print(np.min(v[0]))\n",
    "        \n",
    "        for i in range(len(v)):\n",
    "            #V = (v[i]+abs(np.min(v[i])))/(abs(np.min(v[i]))+abs(np.max(v[i])))\n",
    "            #print(v)\n",
    "            s = findPre(v[i])\n",
    "            ans.append([target[i],s])\n",
    "        if step %10 == 0:\n",
    "            print('[{}/{} ({:.0f}%)]'.format(step * len(data), \n",
    "                                        len(test_dataloader.dataset),\n",
    "                                        100.*step/len(test_dataloader)))\n",
    "\n",
    "    return ans\n",
    "    print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub =  pd.DataFrame(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.rename(index=str, columns={0: \"id\", 1: \"attribute_ids\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
