{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ros/Documents/kaggleData/data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../../kaggleData/data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "lable = pd.read_csv(\"labels.csv\")\n",
    "test = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109237\n",
      "1103\n",
      "7443\n"
     ]
    }
   ],
   "source": [
    "lable_length = len(lable)\n",
    "train_length = len(train)\n",
    "test_length = len(test)\n",
    "print(train_length)\n",
    "print(lable_length)\n",
    "print(test_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 'culture::abruzzi'],\n",
       "       [1, 'culture::achaemenid'],\n",
       "       [2, 'culture::aegean'],\n",
       "       ...,\n",
       "       [1100, 'tag::zeus'],\n",
       "       [1101, 'tag::zigzag pattern'],\n",
       "       [1102, 'tag::zodiac']], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['10023b2cc4ed5f68', '0 1 2'],\n",
       "       ['100fbe75ed8fd887', '0 1 2'],\n",
       "       ['101b627524a04f19', '0 1 2'],\n",
       "       ...,\n",
       "       ['ffe54b454396d97c', '0 1 2'],\n",
       "       ['ffe7d7db4e4aa37f', '0 1 2'],\n",
       "       ['ffed0a4aca0d5457', '0 1 2']], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                     id attribute_ids\n",
       "0     10023b2cc4ed5f68         0 1 2\n",
       "1     100fbe75ed8fd887         0 1 2\n",
       "2     101b627524a04f19         0 1 2\n",
       "3     10234480c41284c6         0 1 2\n",
       "4     1023b0e2636dcea8         0 1 2\n",
       "5      1039cd6cf85845c         0 1 2\n",
       "6      103a5b3f83fbe88         0 1 2\n",
       "7     10413aaae8d6a9a2         0 1 2\n",
       "8     10423822b93a65ab         0 1 2\n",
       "9     1052bf702cb099f7         0 1 2\n",
       "10     10543c918a43a8d         0 1 2\n",
       "11    105c9a3453da79c3         0 1 2\n",
       "12    1060688bbf6eac87         0 1 2\n",
       "13    106a247caeabd15a         0 1 2\n",
       "14    106e21606add59f3         0 1 2\n",
       "15    107c38495881b6c9         0 1 2\n",
       "16    108815dd3752ab64         0 1 2\n",
       "17    10943defdd5d5e89         0 1 2\n",
       "18    10a39a78c44ef27c         0 1 2\n",
       "19     10ab70df067bdb4         0 1 2\n",
       "20    10b28e3de3566582         0 1 2\n",
       "21    10b32964331a6cc3         0 1 2\n",
       "22    10b4562e7fa6f668         0 1 2\n",
       "23    10db1c338e1d822f         0 1 2\n",
       "24    10e0c215f5f3084e         0 1 2\n",
       "25    10e95bead8e0b35b         0 1 2\n",
       "26    1100d7b0f24fee88         0 1 2\n",
       "27    11099b321e8c7066         0 1 2\n",
       "28    110df388fd5c50e4         0 1 2\n",
       "29    113520ea0138f76d         0 1 2\n",
       "...                ...           ...\n",
       "7413  ff2da1f0ed3e3ebe         0 1 2\n",
       "7414  ff3a9fa43f8eab9c         0 1 2\n",
       "7415  ff44490e20740a19         0 1 2\n",
       "7416  ff481bb029678d5d         0 1 2\n",
       "7417  ff4c3570fb7b90d3         0 1 2\n",
       "7418  ff4f548d08414709         0 1 2\n",
       "7419  ff668377a518ea5f         0 1 2\n",
       "7420  ff6a549b2d7a0e76         0 1 2\n",
       "7421  ff6ee1b37c8dc1ae         0 1 2\n",
       "7422  ff85460d6b853b49         0 1 2\n",
       "7423   ff8721b85d1b5a5         0 1 2\n",
       "7424  ff8bef7d0de52b31         0 1 2\n",
       "7425  ff92504c82c41e0f         0 1 2\n",
       "7426  ff9d4b77c124c9f2         0 1 2\n",
       "7427  ff9ddf70cb1c2674         0 1 2\n",
       "7428  ffaf8c3fe0b1d9b6         0 1 2\n",
       "7429  ffb61df4a6734772         0 1 2\n",
       "7430  ffb73f95b8721900         0 1 2\n",
       "7431  ffb937b55755323e         0 1 2\n",
       "7432  ffbcf8b91a8e8ce0         0 1 2\n",
       "7433  ffbf4849bde21b0a         0 1 2\n",
       "7434  ffc96e053345419d         0 1 2\n",
       "7435  ffcb16053099d795         0 1 2\n",
       "7436  ffcf745289465074         0 1 2\n",
       "7437  ffd1372fe67e65f0         0 1 2\n",
       "7438  ffd79eadf642221b         0 1 2\n",
       "7439  ffd96986aa333f4d         0 1 2\n",
       "7440  ffe54b454396d97c         0 1 2\n",
       "7441  ffe7d7db4e4aa37f         0 1 2\n",
       "7442  ffed0a4aca0d5457         0 1 2\n",
       "\n",
       "[7443 rows x 2 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1000483014d91860', '147 616 813'],\n",
       "       ['1000fe2e667721fe', '51 616 734 813'],\n",
       "       ['1001614cb89646ee', '776'],\n",
       "       ...,\n",
       "       ['ffff3e66a42ab868', '156 763'],\n",
       "       ['ffff45b237a32bd5', '121 433'],\n",
       "       ['ffffbf00586b8e37', '462 733 813 1020']], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatData(train,lable_length):\n",
    "    train = np.array(train)\n",
    "    train_data = []\n",
    "    for t in range(train_length):\n",
    "        #v = np.zeros(lable_length)-1\n",
    "        #print(train[t,1])\n",
    "        for s in train[t,1].split(\" \"):\n",
    "            com=''\n",
    "            #print(s.type)\n",
    "            if s=='0':\n",
    "                com = \"cp train/\"+format(train[t,0])+'.png abruzzi'\n",
    "                print(\"copy to abruzzi\")\n",
    "            elif s=='1':\n",
    "                com = \"cp train/\"+format(train[t,0])+'.png achaemenid'\n",
    "                print(\"copy to achaemenid\")\n",
    "            elif s=='2':\n",
    "                com = \"cp train/\"+format(train[t,0])+'.png aegean'\n",
    "                print(\"copy to aegean\")\n",
    "            if not com == '':\n",
    "                os.system(com)\n",
    "                print(\"copied\")\n",
    "            \n",
    "            #print(s)\n",
    "            #v[int(s)] = 1\n",
    "        #train_data.append([train[t,0],v])\n",
    "    #return np.array(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_same(train,lable_length):\n",
    "    train = np.array(train)\n",
    "    train_data = []\n",
    "    for t in range(train_length):\n",
    "        #v = np.zeros(lable_length)-1\n",
    "        #print(train[t,1])\n",
    "        flag = False\n",
    "        for s in train[t,1].split(\" \"):\n",
    "            if int(s)<=397:\n",
    "                if not flag:\n",
    "                    flag = True\n",
    "                else:\n",
    "                    print(\"same\")\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to abruzzi\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to aegean\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n",
      "copy to achaemenid\n",
      "copied\n"
     ]
    }
   ],
   "source": [
    "creatData(train,lable_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainDataset(Dataset):\n",
    "    def __init__(self, train_lib, transform=None):\n",
    "        self.filenames = train_lib[:,0]\n",
    "        self.labels = train_lib[:,1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(\"train/\"+format(self.filenames[idx])+'.png')  # PIL image\n",
    "        image = self.transform(image)\n",
    "        return image, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    def __init__(self, test_lib, transform=None):\n",
    "        test_lib = np.array(test_lib)\n",
    "        self.filenames = test_lib[:,0]\n",
    "        #self.labels = test_lib[:,1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(\"test/\"+format(self.filenames[idx])+'.png')  # PIL image\n",
    "        image = self.transform(image)\n",
    "        return image,self.filenames[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(trainDataset(train_lib, train_transformer), \n",
    "                              batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(testDataset(test, train_transformer),batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_dataloader.dataset[0][1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 128, 128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(train_dataloader.dataset[4][0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionA(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(InceptionA, self).__init__()\n",
    "        self.conv1 = nn.Sequential(       # input  (3,_,_)\n",
    "            #nn.AvgPool2d(3,1,1),          # output  (3,_,_)\n",
    "            nn.Conv2d(in_channels,64,1),  # output  (16,_,_)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(       # input  (3,_,_)\n",
    "            #nn.MaxPool2d(3,1,1),          # output  (3,_,_)\n",
    "            nn.Conv2d(in_channels,48,1),  # output  (16,_,_)\n",
    "            nn.Conv2d(48,64, kernel_size=5, padding=2),  # output  (16,_,_)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(       # input  (3,_,_)\n",
    "            nn.Conv2d(in_channels,64,1),  # output  (16,_,_)\n",
    "            nn.Conv2d(64,96, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(96,96, kernel_size=3, padding=1),\n",
    "        )\n",
    "        \n",
    "        self.conv4 = nn.Sequential(       # input  (3,_,_)\n",
    "            nn.Conv2d(in_channels,64,1),   # output  (8,_,_)\n",
    "            #nn.Conv2d(16,24,3,1,1),      # output  (24,_,_)\n",
    "            #nn.Conv2d(8,16,3,1,1),        # output  (16,_,_)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x4 = self.conv4(x)\n",
    "        \n",
    "        outputs = [x2,x3,x4,x1]\n",
    "        #outputs = [x3,x4,x1]#72\n",
    "        \n",
    "        return torch.cat(outputs,1)       # output  288\n",
    "                                          \n",
    "####################################################################\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(       # input  (3, 128, 128)\n",
    "            nn.Conv2d(3,20,5,1,2),        # output  (20, 128, 128)\n",
    "            InceptionA(in_channels=20),   # output  (288, 128, 128)\n",
    "            nn.MaxPool2d(4),              # output  (288, 64, 64)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(       # input  (64, 64, 64)\n",
    "            nn.Conv2d(288,32,5,1,2),       # output  (32, 64, 64)\n",
    "            InceptionA(in_channels=32),   # output  (288, 64, 64)\n",
    "            nn.MaxPool2d(4),              # output  (288, 32, 32)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(       # input  (288, 32, 32)\n",
    "            nn.Conv2d(288,32,5,1,2),       # output  (32, 32, 32)\n",
    "            nn.MaxPool2d(4),              # output  (32, 16, 16)\n",
    "        )\n",
    "        \n",
    "        self.out1 = nn.Linear(32*24*24, 32*16*8) #fully connected layer  4608 32*24*24\n",
    "        self.out2 = nn.Linear(32*16*8, 32*16*4)\n",
    "        self.out3 = nn.Linear(32*16*4, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        #x = x.view(-1, 32 * 8 * 8)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.out1(x)\n",
    "        x = self.out2(x)\n",
    "        x = self.out3(x)\n",
    "        #x = F.softmax(x, dim=1)\n",
    "        #output = nn.functional.log_softmax(x, dim=1)\n",
    "        return x    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InceptionA(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(20, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(20, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(20, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv4): Sequential(\n",
      "        (0): Conv2d(20, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(288, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InceptionA(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv4): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(288, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out1): Linear(in_features=18432, out_features=4096, bias=True)\n",
      "  (out2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (out3): Linear(in_features=2048, out_features=1103, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(num_classes=lable_length)\n",
    "cnn.cuda()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "#loss_func = torch.nn.MultiLabelMarginLoss()\n",
    "#loss_func = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for step, (x, y) in enumerate(train_dataloader):\n",
    "        data = Variable(x).cuda()   # batch x\n",
    "        target = Variable(y).cuda()   # batch y\n",
    "        #print(data.type())\n",
    "        #print(target.type())\n",
    "        output = cnn(data)               # cnn output\n",
    "        #loss = nn.functional.nll_loss(output, target)\n",
    "        loss = loss_func(output, target.float())   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        if step==0:\n",
    "            start = time.time()\n",
    "            ti = 0\n",
    "        elif step==100:\n",
    "            ti = time.time()-start #total time = ti*(length/100)\n",
    "            #print(ti)\n",
    "            ti = ti*(len(train_dataloader)/100)\n",
    "        if step % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime Remain : {} '.format(epoch, \n",
    "                                                                            step * len(data), \n",
    "                                                                            len(train_dataloader.dataset),\n",
    "                                                                            100.*step/len(train_dataloader), \n",
    "                                                                            loss.data.item(),\n",
    "                                                                            datetime.timedelta(seconds=(ti*(((len(train_dataloader)-step)/len(train_dataloader)))))))\n",
    "            #print('    Time Remain : {}'.format(datetime.timedelta(seconds=(ti*(((length-i)/length))))))\n",
    "    print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/109237 (0%)]\tLoss: 1.001994\tTime Remain : 0:00:00 \n",
      "Train Epoch: 0 [3200/109237 (3%)]\tLoss: 0.105224\tTime Remain : 0:28:33.077049 \n",
      "Train Epoch: 0 [6400/109237 (6%)]\tLoss: 0.033298\tTime Remain : 0:27:41.384923 \n",
      "Train Epoch: 0 [9600/109237 (9%)]\tLoss: 0.017065\tTime Remain : 0:26:49.692797 \n",
      "Train Epoch: 0 [12800/109237 (12%)]\tLoss: 0.018940\tTime Remain : 0:25:58.000672 \n",
      "Train Epoch: 0 [16000/109237 (15%)]\tLoss: 0.015320\tTime Remain : 0:25:06.308546 \n",
      "Train Epoch: 0 [19200/109237 (18%)]\tLoss: 0.014319\tTime Remain : 0:24:14.616420 \n",
      "Train Epoch: 0 [22400/109237 (21%)]\tLoss: 0.012246\tTime Remain : 0:23:22.924294 \n",
      "Train Epoch: 0 [25600/109237 (23%)]\tLoss: 0.012995\tTime Remain : 0:22:31.232168 \n",
      "Train Epoch: 0 [28800/109237 (26%)]\tLoss: 0.011994\tTime Remain : 0:21:39.540043 \n",
      "Train Epoch: 0 [32000/109237 (29%)]\tLoss: 0.012209\tTime Remain : 0:20:47.847917 \n",
      "Train Epoch: 0 [35200/109237 (32%)]\tLoss: 0.012556\tTime Remain : 0:19:56.155791 \n",
      "Train Epoch: 0 [38400/109237 (35%)]\tLoss: 0.012294\tTime Remain : 0:19:04.463665 \n",
      "Train Epoch: 0 [41600/109237 (38%)]\tLoss: 0.012548\tTime Remain : 0:18:12.771539 \n",
      "Train Epoch: 0 [44800/109237 (41%)]\tLoss: 0.011332\tTime Remain : 0:17:21.079414 \n",
      "Train Epoch: 0 [48000/109237 (44%)]\tLoss: 0.013481\tTime Remain : 0:16:29.387288 \n",
      "Train Epoch: 0 [51200/109237 (47%)]\tLoss: 0.012799\tTime Remain : 0:15:37.695162 \n",
      "Train Epoch: 0 [54400/109237 (50%)]\tLoss: 0.012002\tTime Remain : 0:14:46.003036 \n",
      "Train Epoch: 0 [57600/109237 (53%)]\tLoss: 0.012464\tTime Remain : 0:13:54.310910 \n",
      "Train Epoch: 0 [60800/109237 (56%)]\tLoss: 0.011048\tTime Remain : 0:13:02.618785 \n",
      "Train Epoch: 0 [64000/109237 (59%)]\tLoss: 0.009725\tTime Remain : 0:12:10.926659 \n",
      "Train Epoch: 0 [67200/109237 (62%)]\tLoss: 0.011101\tTime Remain : 0:11:19.234533 \n",
      "Train Epoch: 0 [70400/109237 (64%)]\tLoss: 0.012185\tTime Remain : 0:10:27.542407 \n",
      "Train Epoch: 0 [73600/109237 (67%)]\tLoss: 0.010845\tTime Remain : 0:09:35.850281 \n",
      "Train Epoch: 0 [76800/109237 (70%)]\tLoss: 0.012200\tTime Remain : 0:08:44.158156 \n",
      "Train Epoch: 0 [80000/109237 (73%)]\tLoss: 0.011707\tTime Remain : 0:07:52.466030 \n",
      "Train Epoch: 0 [83200/109237 (76%)]\tLoss: 0.012110\tTime Remain : 0:07:00.773904 \n",
      "Train Epoch: 0 [86400/109237 (79%)]\tLoss: 0.010840\tTime Remain : 0:06:09.081778 \n",
      "Train Epoch: 0 [89600/109237 (82%)]\tLoss: 0.011652\tTime Remain : 0:05:17.389652 \n",
      "Train Epoch: 0 [92800/109237 (85%)]\tLoss: 0.011453\tTime Remain : 0:04:25.697527 \n",
      "Train Epoch: 0 [96000/109237 (88%)]\tLoss: 0.010307\tTime Remain : 0:03:34.005401 \n",
      "Train Epoch: 0 [99200/109237 (91%)]\tLoss: 0.011636\tTime Remain : 0:02:42.313275 \n",
      "Train Epoch: 0 [102400/109237 (94%)]\tLoss: 0.011785\tTime Remain : 0:01:50.621149 \n",
      "Train Epoch: 0 [105600/109237 (97%)]\tLoss: 0.010659\tTime Remain : 0:00:58.929023 \n",
      "Train Epoch: 0 [108800/109237 (100%)]\tLoss: 0.013200\tTime Remain : 0:00:07.236898 \n",
      "Finish\n",
      "Train Epoch: 1 [0/109237 (0%)]\tLoss: 0.011866\tTime Remain : 0:00:00 \n",
      "Train Epoch: 1 [3200/109237 (3%)]\tLoss: 0.010979\tTime Remain : 0:30:04.952912 \n",
      "Train Epoch: 1 [6400/109237 (6%)]\tLoss: 0.010244\tTime Remain : 0:29:10.488431 \n",
      "Train Epoch: 1 [9600/109237 (9%)]\tLoss: 0.011546\tTime Remain : 0:28:16.023949 \n",
      "Train Epoch: 1 [12800/109237 (12%)]\tLoss: 0.011793\tTime Remain : 0:27:21.559468 \n",
      "Train Epoch: 1 [16000/109237 (15%)]\tLoss: 0.012531\tTime Remain : 0:26:27.094987 \n",
      "Train Epoch: 1 [19200/109237 (18%)]\tLoss: 0.010579\tTime Remain : 0:25:32.630505 \n",
      "Train Epoch: 1 [22400/109237 (21%)]\tLoss: 0.010363\tTime Remain : 0:24:38.166024 \n",
      "Train Epoch: 1 [25600/109237 (23%)]\tLoss: 0.011427\tTime Remain : 0:23:43.701543 \n",
      "Train Epoch: 1 [28800/109237 (26%)]\tLoss: 0.010240\tTime Remain : 0:22:49.237061 \n",
      "Train Epoch: 1 [32000/109237 (29%)]\tLoss: 0.010002\tTime Remain : 0:21:54.772580 \n",
      "Train Epoch: 1 [35200/109237 (32%)]\tLoss: 0.011541\tTime Remain : 0:21:00.308099 \n",
      "Train Epoch: 1 [38400/109237 (35%)]\tLoss: 0.011458\tTime Remain : 0:20:05.843617 \n",
      "Train Epoch: 1 [41600/109237 (38%)]\tLoss: 0.012274\tTime Remain : 0:19:11.379136 \n",
      "Train Epoch: 1 [44800/109237 (41%)]\tLoss: 0.009422\tTime Remain : 0:18:16.914654 \n",
      "Train Epoch: 1 [48000/109237 (44%)]\tLoss: 0.011247\tTime Remain : 0:17:22.450173 \n",
      "Train Epoch: 1 [51200/109237 (47%)]\tLoss: 0.010748\tTime Remain : 0:16:27.985692 \n",
      "Train Epoch: 1 [54400/109237 (50%)]\tLoss: 0.011191\tTime Remain : 0:15:33.521210 \n",
      "Train Epoch: 1 [57600/109237 (53%)]\tLoss: 0.010549\tTime Remain : 0:14:39.056729 \n",
      "Train Epoch: 1 [60800/109237 (56%)]\tLoss: 0.012177\tTime Remain : 0:13:44.592248 \n",
      "Train Epoch: 1 [64000/109237 (59%)]\tLoss: 0.010437\tTime Remain : 0:12:50.127766 \n",
      "Train Epoch: 1 [67200/109237 (62%)]\tLoss: 0.010886\tTime Remain : 0:11:55.663285 \n",
      "Train Epoch: 1 [70400/109237 (64%)]\tLoss: 0.011013\tTime Remain : 0:11:01.198804 \n",
      "Train Epoch: 1 [73600/109237 (67%)]\tLoss: 0.011921\tTime Remain : 0:10:06.734322 \n",
      "Train Epoch: 1 [76800/109237 (70%)]\tLoss: 0.011235\tTime Remain : 0:09:12.269841 \n",
      "Train Epoch: 1 [80000/109237 (73%)]\tLoss: 0.010222\tTime Remain : 0:08:17.805360 \n",
      "Train Epoch: 1 [83200/109237 (76%)]\tLoss: 0.012473\tTime Remain : 0:07:23.340878 \n",
      "Train Epoch: 1 [86400/109237 (79%)]\tLoss: 0.010765\tTime Remain : 0:06:28.876397 \n",
      "Train Epoch: 1 [89600/109237 (82%)]\tLoss: 0.010312\tTime Remain : 0:05:34.411916 \n",
      "Train Epoch: 1 [92800/109237 (85%)]\tLoss: 0.011671\tTime Remain : 0:04:39.947434 \n",
      "Train Epoch: 1 [96000/109237 (88%)]\tLoss: 0.011648\tTime Remain : 0:03:45.482953 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1d8dd82aac92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-2456196744ed>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# batch x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# batch y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#print(data.type())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a1b5532ba046>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# PIL image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1815\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m                         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodermaxblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                                 \u001b[0;31m# truncated png/gif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36mload_read\u001b[0;34m(self, read_bytes)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__idat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__idat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mread_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ros/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ros/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type InceptionA. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(cnn, 'net.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPre(output):\n",
    "    a = ''\n",
    "    output = np.array(output)\n",
    "    #output = np.where(output > 0.8,1,0)\n",
    "    for i in range(len(output)):\n",
    "        if output[i]>0.9555:\n",
    "            a = a + format(i)+' '\n",
    "    print(a)\n",
    "    return a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model = model.eval()\n",
    "    ans = []\n",
    "    for step, (x, y) in enumerate(test_dataloader):\n",
    "        data = Variable(x).cuda()\n",
    "        target = y\n",
    "        output = model(data)\n",
    "        v = output.cpu().detach()\n",
    "        \n",
    "        v = np.array(v)\n",
    "        v = preprocessing.minmax_scale(v, feature_range=(-10,1))\n",
    "        #v = min_max_scaler.fit_transform(v)\n",
    "#         v = torch.from_numpy(v)\n",
    "#         v = F.softmax(v, dim=0)\n",
    "#         v = np.array(v)\n",
    "        #v = sigmoid(v)\n",
    "        print(np.max(v[0]))\n",
    "        print(np.min(v[0]))\n",
    "        \n",
    "        for i in range(len(v)):\n",
    "            #V = (v[i]+abs(np.min(v[i])))/(abs(np.min(v[i]))+abs(np.max(v[i])))\n",
    "            #print(v)\n",
    "            s = findPre(v[i])\n",
    "            ans.append([target[i],s])\n",
    "        if step %10 == 0:\n",
    "            print('[{}/{} ({:.0f}%)]'.format(step * len(data), \n",
    "                                        len(test_dataloader.dataset),\n",
    "                                        100.*step/len(test_dataloader)))\n",
    "\n",
    "    return ans\n",
    "    print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 5.92 GiB total capacity; 4.91 GiB already allocated; 10.69 MiB free; 207.78 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-402559408cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-76cc32cc7b11>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-a740d98b0603>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#x = x.view(-1, 32 * 8 * 8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-a740d98b0603>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 5.92 GiB total capacity; 4.91 GiB already allocated; 10.69 MiB free; 207.78 MiB cached)"
     ]
    }
   ],
   "source": [
    "sub = test(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub =  pd.DataFrame(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.rename(index=str, columns={0: \"id\", 1: \"attribute_ids\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
