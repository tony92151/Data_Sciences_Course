{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ros/Documents/kaggleData/data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../../kaggleData/data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "lable = pd.read_csv(\"labels.csv\")\n",
    "test = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109237\n",
      "1103\n"
     ]
    }
   ],
   "source": [
    "lable_length = len(lable)\n",
    "train_length = len(train)\n",
    "test_length = len(test)\n",
    "print(train_length)\n",
    "print(lable_length)\n",
    "print(test_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1000483014d91860', '147 616 813'],\n",
       "       ['1000fe2e667721fe', '51 616 734 813'],\n",
       "       ['1001614cb89646ee', '776'],\n",
       "       ...,\n",
       "       ['ffff3e66a42ab868', '156 763'],\n",
       "       ['ffff45b237a32bd5', '121 433'],\n",
       "       ['ffffbf00586b8e37', '462 733 813 1020']], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatData(train,lable_length):\n",
    "    train = np.array(train)\n",
    "    train_data = []\n",
    "    for t in range(train_length):\n",
    "        v = np.zeros(lable_length)\n",
    "        #print(train[t,1])\n",
    "        for s in train[t,1].split(\" \"):\n",
    "            #print(s)\n",
    "            v[int(s)] = 1\n",
    "        train_data.append([train[t,0],v])\n",
    "    return np.array(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1000483014d91860' array([0., 0., 0., ..., 0., 0., 0.])]\n",
      " ['1000fe2e667721fe' array([0., 0., 0., ..., 0., 0., 0.])]\n",
      " ['1001614cb89646ee' array([0., 0., 0., ..., 0., 0., 0.])]\n",
      " ...\n",
      " ['ffff3e66a42ab868' array([0., 0., 0., ..., 0., 0., 0.])]\n",
      " ['ffff45b237a32bd5' array([0., 0., 0., ..., 0., 0., 0.])]\n",
      " ['ffffbf00586b8e37' array([0., 0., 0., ..., 0., 0., 0.])]]\n"
     ]
    }
   ],
   "source": [
    "train_lib = creatData(train,lable_length)\n",
    "print(train_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = transforms.Compose([\n",
    "  transforms.Resize((128,128)),              # resize the image to \n",
    "  #transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
    "  transforms.ToTensor()])             # transform it into a PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainDataset(Dataset):\n",
    "    def __init__(self, train_lib, transform=None):\n",
    "        self.filenames = train_lib[:,0]\n",
    "        self.labels = train_lib[:,1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(\"train/\"+format(self.filenames[idx])+'.png')  # PIL image\n",
    "        image = self.transform(image)\n",
    "        return image, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    def __init__(self, test_lib, transform=None):\n",
    "        test_lib = np.array(test_lib)\n",
    "        self.filenames = test_lib[:,0]\n",
    "        #self.labels = test_lib[:,1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(\"test/\"+format(self.filenames[idx])+'.png')  # PIL image\n",
    "        image = self.transform(image)\n",
    "        return image,self.filenames[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(testDataset(test, train_transformer),batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(trainDataset(train_lib, train_transformer), \n",
    "                              batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 128, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(train_dataloader.dataset[4][0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionA(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, pool_features):\n",
    "        super(InceptionA, self).__init__()\n",
    "        self.branch1x1 = nn.Conv2d(in_channels, 64, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = nn.Conv2d(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = nn.Conv2d(48, 64, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = nn.Conv2d(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = nn.Conv2d(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = nn.Conv2d(96, 96, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = nn.Conv2d(in_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return torch.cat(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionA(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(InceptionA, self).__init__()\n",
    "        self.conv1 = nn.Sequential(       # input  (3,_,_)\n",
    "            #nn.AvgPool2d(3,1,1),          # output  (3,_,_)\n",
    "            nn.Conv2d(in_channels,64,1),  # output  (16,_,_)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(       # input  (3,_,_)\n",
    "            #nn.MaxPool2d(3,1,1),          # output  (3,_,_)\n",
    "            nn.Conv2d(in_channels,48,1),  # output  (16,_,_)\n",
    "            nn.Conv2d(48,64, kernel_size=5, padding=2),  # output  (16,_,_)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(       # input  (3,_,_)\n",
    "            nn.Conv2d(in_channels,64,1),  # output  (16,_,_)\n",
    "            nn.Conv2d(64,96, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(96,96, kernel_size=3, padding=1),\n",
    "        )\n",
    "        \n",
    "        self.conv4 = nn.Sequential(       # input  (3,_,_)\n",
    "            nn.Conv2d(in_channels,64,1),   # output  (8,_,_)\n",
    "            #nn.Conv2d(16,24,3,1,1),      # output  (24,_,_)\n",
    "            #nn.Conv2d(8,16,3,1,1),        # output  (16,_,_)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x4 = self.conv4(x)\n",
    "        \n",
    "        outputs = [x2,x3,x4,x1]\n",
    "        #outputs = [x3,x4,x1]#72\n",
    "        \n",
    "        return torch.cat(outputs,1)       # output  288\n",
    "                                          \n",
    "####################################################################\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(       # input  (3, 128, 128)\n",
    "            nn.Conv2d(3,20,5,1,2),        # output  (20, 128, 128)\n",
    "            InceptionA(in_channels=20),   # output  (288, 128, 128)\n",
    "            nn.MaxPool2d(4),              # output  (288, 64, 64)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(       # input  (64, 64, 64)\n",
    "            nn.Conv2d(288,32,5,1,2),       # output  (32, 64, 64)\n",
    "            InceptionA(in_channels=32),   # output  (288, 64, 64)\n",
    "            nn.MaxPool2d(4),              # output  (288, 32, 32)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(       # input  (288, 32, 32)\n",
    "            nn.Conv2d(288,32,5,1,2),       # output  (32, 32, 32)\n",
    "            nn.MaxPool2d(4),              # output  (32, 16, 16)\n",
    "        )\n",
    "        \n",
    "        self.out1 = nn.Linear(32*24*24, 32*16*8) #fully connected layer\n",
    "        self.out2 = nn.Linear(32*16*8, 32*16*4)\n",
    "        self.out3 = nn.Linear(32*16*4, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        #x = x.view(-1, 32 * 8 * 8)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.out1(x)\n",
    "        x = self.out2(x)\n",
    "        x = self.out3(x)\n",
    "        #output = nn.functional.log_softmax(x, dim=1)\n",
    "        return x    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InceptionA(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(20, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(20, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(20, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv4): Sequential(\n",
      "        (0): Conv2d(20, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(288, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InceptionA(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv4): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(288, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out1): Linear(in_features=18432, out_features=4096, bias=True)\n",
      "  (out2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (out3): Linear(in_features=2048, out_features=1103, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(num_classes=lable_length)\n",
    "cnn.cuda()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "loss_func = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for step, (x, y) in enumerate(train_dataloader):\n",
    "        data = Variable(x).cuda()   # batch x\n",
    "        target = Variable(y).cuda()   # batch y\n",
    "        #print(data.type())\n",
    "        #print(target.type())\n",
    "        output = cnn(data)               # cnn output\n",
    "        #loss = nn.functional.nll_loss(output, target)\n",
    "        loss = loss_func(output, target.float())   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "        if step==0:\n",
    "            start = time.time()\n",
    "            ti = 0\n",
    "        elif step==100:\n",
    "            ti = time.time()-start #total time = ti*(length/100)\n",
    "            #print(ti)\n",
    "            ti = ti*(len(train_dataloader)/100)\n",
    "        if step % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTime Remain : {} '.format(epoch, \n",
    "                                                                            step * len(data), \n",
    "                                                                            len(train_dataloader.dataset),\n",
    "                                                                            100.*step/len(train_dataloader), \n",
    "                                                                            loss.data.item(),\n",
    "                                                                            datetime.timedelta(seconds=(ti*(((len(train_dataloader)-step)/len(train_dataloader)))))))\n",
    "            #print('    Time Remain : {}'.format(datetime.timedelta(seconds=(ti*(((length-i)/length))))))\n",
    "    print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/109237 (0%)]\tLoss: 0.003467\tTime Remain : 0:00:00 \n",
      "Train Epoch: 0 [3200/109237 (3%)]\tLoss: 0.040877\tTime Remain : 0:27:30.235071 \n",
      "Train Epoch: 0 [6400/109237 (6%)]\tLoss: 0.007808\tTime Remain : 0:26:40.439203 \n",
      "Train Epoch: 0 [9600/109237 (9%)]\tLoss: 0.006563\tTime Remain : 0:25:50.643334 \n",
      "Train Epoch: 0 [12800/109237 (12%)]\tLoss: 0.005745\tTime Remain : 0:25:00.847466 \n",
      "Train Epoch: 0 [16000/109237 (15%)]\tLoss: 0.004921\tTime Remain : 0:24:11.051598 \n",
      "Train Epoch: 0 [19200/109237 (18%)]\tLoss: 0.004638\tTime Remain : 0:23:21.255730 \n",
      "Train Epoch: 0 [22400/109237 (21%)]\tLoss: 0.004451\tTime Remain : 0:22:31.459862 \n",
      "Train Epoch: 0 [25600/109237 (23%)]\tLoss: 0.004028\tTime Remain : 0:21:41.663994 \n",
      "Train Epoch: 0 [28800/109237 (26%)]\tLoss: 0.003460\tTime Remain : 0:20:51.868126 \n",
      "Train Epoch: 0 [32000/109237 (29%)]\tLoss: 0.003554\tTime Remain : 0:20:02.072257 \n",
      "Train Epoch: 0 [35200/109237 (32%)]\tLoss: 0.004397\tTime Remain : 0:19:12.276389 \n",
      "Train Epoch: 0 [38400/109237 (35%)]\tLoss: 0.003392\tTime Remain : 0:18:22.480521 \n",
      "Train Epoch: 0 [41600/109237 (38%)]\tLoss: 0.003097\tTime Remain : 0:17:32.684653 \n",
      "Train Epoch: 0 [44800/109237 (41%)]\tLoss: 0.003305\tTime Remain : 0:16:42.888785 \n",
      "Train Epoch: 0 [48000/109237 (44%)]\tLoss: 0.003338\tTime Remain : 0:15:53.092917 \n",
      "Train Epoch: 0 [51200/109237 (47%)]\tLoss: 0.002864\tTime Remain : 0:15:03.297048 \n",
      "Train Epoch: 0 [54400/109237 (50%)]\tLoss: 0.003072\tTime Remain : 0:14:13.501180 \n",
      "Train Epoch: 0 [57600/109237 (53%)]\tLoss: 0.003145\tTime Remain : 0:13:23.705312 \n",
      "Train Epoch: 0 [60800/109237 (56%)]\tLoss: 0.003431\tTime Remain : 0:12:33.909444 \n",
      "Train Epoch: 0 [64000/109237 (59%)]\tLoss: 0.003061\tTime Remain : 0:11:44.113576 \n",
      "Train Epoch: 0 [67200/109237 (62%)]\tLoss: 0.003094\tTime Remain : 0:10:54.317708 \n",
      "Train Epoch: 0 [70400/109237 (64%)]\tLoss: 0.003314\tTime Remain : 0:10:04.521839 \n",
      "Train Epoch: 0 [73600/109237 (67%)]\tLoss: 0.003005\tTime Remain : 0:09:14.725971 \n",
      "Train Epoch: 0 [76800/109237 (70%)]\tLoss: 0.002885\tTime Remain : 0:08:24.930103 \n",
      "Train Epoch: 0 [80000/109237 (73%)]\tLoss: 0.003014\tTime Remain : 0:07:35.134235 \n",
      "Train Epoch: 0 [83200/109237 (76%)]\tLoss: 0.003075\tTime Remain : 0:06:45.338367 \n",
      "Train Epoch: 0 [86400/109237 (79%)]\tLoss: 0.002896\tTime Remain : 0:05:55.542499 \n",
      "Train Epoch: 0 [89600/109237 (82%)]\tLoss: 0.003123\tTime Remain : 0:05:05.746630 \n",
      "Train Epoch: 0 [92800/109237 (85%)]\tLoss: 0.003002\tTime Remain : 0:04:15.950762 \n",
      "Train Epoch: 0 [96000/109237 (88%)]\tLoss: 0.002564\tTime Remain : 0:03:26.154894 \n",
      "Train Epoch: 0 [99200/109237 (91%)]\tLoss: 0.002925\tTime Remain : 0:02:36.359026 \n",
      "Train Epoch: 0 [102400/109237 (94%)]\tLoss: 0.002613\tTime Remain : 0:01:46.563158 \n",
      "Train Epoch: 0 [105600/109237 (97%)]\tLoss: 0.002834\tTime Remain : 0:00:56.767290 \n",
      "Train Epoch: 0 [108800/109237 (100%)]\tLoss: 0.003016\tTime Remain : 0:00:06.971422 \n",
      "Finish\n",
      "Train Epoch: 1 [0/109237 (0%)]\tLoss: 0.002987\tTime Remain : 0:00:00 \n",
      "Train Epoch: 1 [3200/109237 (3%)]\tLoss: 0.002804\tTime Remain : 0:28:54.633207 \n",
      "Train Epoch: 1 [6400/109237 (6%)]\tLoss: 0.002910\tTime Remain : 0:28:02.290623 \n",
      "Train Epoch: 1 [9600/109237 (9%)]\tLoss: 0.002827\tTime Remain : 0:27:09.948040 \n",
      "Train Epoch: 1 [12800/109237 (12%)]\tLoss: 0.002915\tTime Remain : 0:26:17.605457 \n",
      "Train Epoch: 1 [16000/109237 (15%)]\tLoss: 0.002885\tTime Remain : 0:25:25.262874 \n",
      "Train Epoch: 1 [19200/109237 (18%)]\tLoss: 0.002747\tTime Remain : 0:24:32.920291 \n",
      "Train Epoch: 1 [22400/109237 (21%)]\tLoss: 0.003124\tTime Remain : 0:23:40.577707 \n",
      "Train Epoch: 1 [25600/109237 (23%)]\tLoss: 0.003286\tTime Remain : 0:22:48.235124 \n",
      "Train Epoch: 1 [28800/109237 (26%)]\tLoss: 0.003081\tTime Remain : 0:21:55.892541 \n",
      "Train Epoch: 1 [32000/109237 (29%)]\tLoss: 0.002766\tTime Remain : 0:21:03.549958 \n",
      "Train Epoch: 1 [35200/109237 (32%)]\tLoss: 0.002877\tTime Remain : 0:20:11.207375 \n",
      "Train Epoch: 1 [38400/109237 (35%)]\tLoss: 0.002755\tTime Remain : 0:19:18.864792 \n",
      "Train Epoch: 1 [41600/109237 (38%)]\tLoss: 0.002671\tTime Remain : 0:18:26.522208 \n",
      "Train Epoch: 1 [44800/109237 (41%)]\tLoss: 0.002957\tTime Remain : 0:17:34.179625 \n",
      "Train Epoch: 1 [48000/109237 (44%)]\tLoss: 0.002974\tTime Remain : 0:16:41.837042 \n",
      "Train Epoch: 1 [51200/109237 (47%)]\tLoss: 0.003141\tTime Remain : 0:15:49.494459 \n",
      "Train Epoch: 1 [54400/109237 (50%)]\tLoss: 0.003137\tTime Remain : 0:14:57.151876 \n",
      "Train Epoch: 1 [57600/109237 (53%)]\tLoss: 0.002735\tTime Remain : 0:14:04.809293 \n",
      "Train Epoch: 1 [60800/109237 (56%)]\tLoss: 0.002705\tTime Remain : 0:13:12.466709 \n",
      "Train Epoch: 1 [64000/109237 (59%)]\tLoss: 0.003351\tTime Remain : 0:12:20.124126 \n",
      "Train Epoch: 1 [67200/109237 (62%)]\tLoss: 0.002673\tTime Remain : 0:11:27.781543 \n",
      "Train Epoch: 1 [70400/109237 (64%)]\tLoss: 0.002786\tTime Remain : 0:10:35.438960 \n",
      "Train Epoch: 1 [73600/109237 (67%)]\tLoss: 0.002923\tTime Remain : 0:09:43.096377 \n",
      "Train Epoch: 1 [76800/109237 (70%)]\tLoss: 0.003130\tTime Remain : 0:08:50.753793 \n",
      "Train Epoch: 1 [80000/109237 (73%)]\tLoss: 0.003076\tTime Remain : 0:07:58.411210 \n",
      "Train Epoch: 1 [83200/109237 (76%)]\tLoss: 0.002794\tTime Remain : 0:07:06.068627 \n",
      "Train Epoch: 1 [86400/109237 (79%)]\tLoss: 0.002625\tTime Remain : 0:06:13.726044 \n",
      "Train Epoch: 1 [89600/109237 (82%)]\tLoss: 0.002888\tTime Remain : 0:05:21.383461 \n",
      "Train Epoch: 1 [92800/109237 (85%)]\tLoss: 0.002953\tTime Remain : 0:04:29.040878 \n",
      "Train Epoch: 1 [96000/109237 (88%)]\tLoss: 0.002966\tTime Remain : 0:03:36.698294 \n",
      "Train Epoch: 1 [99200/109237 (91%)]\tLoss: 0.003091\tTime Remain : 0:02:44.355711 \n",
      "Train Epoch: 1 [102400/109237 (94%)]\tLoss: 0.003393\tTime Remain : 0:01:52.013128 \n",
      "Train Epoch: 1 [105600/109237 (97%)]\tLoss: 0.003250\tTime Remain : 0:00:59.670545 \n",
      "Train Epoch: 1 [108800/109237 (100%)]\tLoss: 0.002634\tTime Remain : 0:00:07.327962 \n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    \n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ros/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ros/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type InceptionA. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(cnn, 'net.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPre(output):\n",
    "    a = ''\n",
    "    output = np.array(output)\n",
    "    #output = np.where(output > 0.8,1,0)\n",
    "    for i in range(len(output)):\n",
    "        if output[i]>0.5:\n",
    "            a = a + format(i)+' '\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model = model.eval()\n",
    "    for step, (x, y) in enumerate(test_dataloader):\n",
    "        data = Variable(x).cuda()\n",
    "        target = y\n",
    "        output = model(data)\n",
    "        #print(np.max(output.cpu().detach().numpy()[0]))\n",
    "        findPre(output.cpu().detach().numpy()[0])\n",
    "\n",
    "\n",
    "    print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 576.00 MiB (GPU 0; 5.92 GiB total capacity; 4.69 GiB already allocated; 114.88 MiB free; 329.93 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d9674693eb5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-6b90f1b2734e>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#print(np.max(output.cpu().detach().numpy()[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfindPre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b16bfcaf877d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#x = x.view(-1, 32 * 8 * 8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch_g/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b16bfcaf877d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#outputs = [x3,x4,x1]#72\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# output  288\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m####################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 576.00 MiB (GPU 0; 5.92 GiB total capacity; 4.69 GiB already allocated; 114.88 MiB free; 329.93 MiB cached)"
     ]
    }
   ],
   "source": [
    "test(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
