{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dsai2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tIXoKKUi91qi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "#torch.set_default_tensor_type('torch.cuda.FloatTensor')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WhzPO7NRo42i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 數據產生器，亂數產生出\"100+150 \"及 \"250 \"等數據"
      ]
    },
    {
      "metadata": {
        "id": "9ayrHp8gS71r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def creatData(length):\n",
        "  que = []\n",
        "  ans = []\n",
        "  for i in range(length):\n",
        "    x = random.randint(1,1000)\n",
        "    y = random.randint(1,999)\n",
        "    a = x+y\n",
        "    str1 = str(x)+'+'+str(y)\n",
        "    str2 = str(a)\n",
        "    while len(str1)<8: \n",
        "      str1 = str1+' '\n",
        "    while len(str2)<4: \n",
        "      str2 = str2+' '\n",
        "    que.append(str1)\n",
        "    ans.append(str2)\n",
        "  return que,ans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v13Ksupd2yJb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dict1 = { ' ': [1,0,0,0,0,0,0,0,0,0,0,0],\n",
        "         '+': [0,1,0,0,0,0,0,0,0,0,0,0],\n",
        "         '0': [0,0,1,0,0,0,0,0,0,0,0,0],\n",
        "         '1': [0,0,0,1,0,0,0,0,0,0,0,0],\n",
        "         '2': [0,0,0,0,1,0,0,0,0,0,0,0],\n",
        "         '3': [0,0,0,0,0,1,0,0,0,0,0,0],\n",
        "         '4': [0,0,0,0,0,0,1,0,0,0,0,0],\n",
        "         '5': [0,0,0,0,0,0,0,1,0,0,0,0],\n",
        "         '6': [0,0,0,0,0,0,0,0,1,0,0,0],\n",
        "         '7': [0,0,0,0,0,0,0,0,0,1,0,0],\n",
        "         '8': [0,0,0,0,0,0,0,0,0,0,1,0],\n",
        "         '9': [0,0,0,0,0,0,0,0,0,0,0,1]}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "etRljMOYposK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 將文字依照上方字典做 Feature Engineering"
      ]
    },
    {
      "metadata": {
        "id": "HjIHxxyZyexQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ceratDataSet(que,ans):\n",
        "  #global = dict\n",
        "  Q,A = [],[]\n",
        "  for i in range(len(que)):\n",
        "    a,b = [],[]\n",
        "    for n in range(len(que[0])):\n",
        "      a1 = dict1[que[i][n]]\n",
        "      a = a+a1\n",
        "    for k in range(len(ans[0])):\n",
        "      a2 = dict1[ans[i][k]]\n",
        "      b = b+a2\n",
        "    Q.append(a)\n",
        "    A.append(b)\n",
        "  return np.array(Q),np.array(A)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PV2yzIq_pyQG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# pytorch數據集"
      ]
    },
    {
      "metadata": {
        "id": "r1odkWaLPDVV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self, qua, ans):\n",
        "    self.Q = qua\n",
        "    self.A = ans\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.A)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      q = self.Q[idx]\n",
        "      a = self.A[idx]\n",
        "      return q,a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hscb5zVp4o8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "que,ans = creatData(100000)\n",
        "\n",
        "persentage = 0.8\n",
        "\n",
        "Q,A = ceratDataSet(que,ans)\n",
        "fron = int(len(Q)*persentage)\n",
        "\n",
        "\n",
        "Q_train = Q[:fron]\n",
        "A_train = A[:fron]\n",
        "\n",
        "Q_test = Q[fron:]\n",
        "A_test = A[fron:]\n",
        "\n",
        "train_dataloader = DataLoader(MyDataset(Q_train,A_train),batch_size=100, shuffle=True)\n",
        "test_dataloader = DataLoader(MyDataset(Q_test,A_test), shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7AONQ83fse1Q",
        "colab_type": "code",
        "outputId": "6c66ea57-c122-46b8-eb32-baf5f7d85a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "print(use_gpu)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CuwoJhobp8OQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 定義NN，這邊用6層 linear connection 做連接"
      ]
    },
    {
      "metadata": {
        "id": "6ELVjLC5-o17",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.out1 = torch.nn.Linear(12*8,120)\n",
        "    self.out2 = torch.nn.Linear(120,180)\n",
        "    self.out3 = torch.nn.Linear(180,240)\n",
        "    self.out4 = torch.nn.Linear(240,300)\n",
        "    self.out5 = torch.nn.Linear(300,120)\n",
        "    self.out6 = torch.nn.Linear(120,12*4)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print(self.out1.weight.type())\n",
        "    #print(x.shape)\n",
        "    x = self.out1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.out2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.out3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.out4(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.out5(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.out6(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hghwnMkHvyGs",
        "colab_type": "code",
        "outputId": "24dcd9a1-ee7f-4884-9163-fc9ca11d89e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "\n",
        "print(type(model))\n",
        "\n",
        "if use_gpu:\n",
        "  model = model.cuda()\n",
        "print(model)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class '__main__.CNN'>\n",
            "CNN(\n",
            "  (out1): Linear(in_features=96, out_features=120, bias=True)\n",
            "  (out2): Linear(in_features=120, out_features=180, bias=True)\n",
            "  (out3): Linear(in_features=180, out_features=240, bias=True)\n",
            "  (out4): Linear(in_features=240, out_features=300, bias=True)\n",
            "  (out5): Linear(in_features=300, out_features=120, bias=True)\n",
            "  (out6): Linear(in_features=120, out_features=48, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jutQad1vyX6i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCH = 50\n",
        "\n",
        "loss_func = torch.nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.002)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kpXXWJStqM0N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 訓練 50 EPOCH"
      ]
    },
    {
      "metadata": {
        "id": "w1f_XGw-whoF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "  for step, (x, y) in enumerate(train_dataloader):\n",
        "      data = x.type(torch.cuda.FloatTensor)\n",
        "      target = y.type(torch.cuda.FloatTensor)\n",
        "\n",
        "      output = model(data)               # cnn output\n",
        "\n",
        "      loss = loss_func(output, target)   # cross entropy loss\n",
        "      optimizer.zero_grad()           # clear gradients for this training step\n",
        "      loss.backward()                 # backpropagation, compute gradients\n",
        "      optimizer.step()                # apply gradients\n",
        "\n",
        "      if step % 200 == 0:\n",
        "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, \n",
        "         step * len(data), len(train_dataloader.dataset),100. * step / len(train_dataloader), loss.data.item()))\n",
        "  print(\"Finish\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bU8GmsOPR1DJ",
        "colab_type": "code",
        "outputId": "697e89d5-7b24-4cc4-907a-c80901bcabca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4329
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(1,EPOCH):\n",
        "    train(epoch)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/80000 (0%)]\tLoss: 0.088777\n",
            "Train Epoch: 1 [20000/80000 (25%)]\tLoss: 0.053467\n",
            "Train Epoch: 1 [40000/80000 (50%)]\tLoss: 0.047470\n",
            "Train Epoch: 1 [60000/80000 (75%)]\tLoss: 0.044307\n",
            "Finish\n",
            "Train Epoch: 2 [0/80000 (0%)]\tLoss: 0.041437\n",
            "Train Epoch: 2 [20000/80000 (25%)]\tLoss: 0.039959\n",
            "Train Epoch: 2 [40000/80000 (50%)]\tLoss: 0.040483\n",
            "Train Epoch: 2 [60000/80000 (75%)]\tLoss: 0.039719\n",
            "Finish\n",
            "Train Epoch: 3 [0/80000 (0%)]\tLoss: 0.039989\n",
            "Train Epoch: 3 [20000/80000 (25%)]\tLoss: 0.038601\n",
            "Train Epoch: 3 [40000/80000 (50%)]\tLoss: 0.038922\n",
            "Train Epoch: 3 [60000/80000 (75%)]\tLoss: 0.038507\n",
            "Finish\n",
            "Train Epoch: 4 [0/80000 (0%)]\tLoss: 0.038948\n",
            "Train Epoch: 4 [20000/80000 (25%)]\tLoss: 0.038576\n",
            "Train Epoch: 4 [40000/80000 (50%)]\tLoss: 0.038885\n",
            "Train Epoch: 4 [60000/80000 (75%)]\tLoss: 0.037446\n",
            "Finish\n",
            "Train Epoch: 5 [0/80000 (0%)]\tLoss: 0.036462\n",
            "Train Epoch: 5 [20000/80000 (25%)]\tLoss: 0.034798\n",
            "Train Epoch: 5 [40000/80000 (50%)]\tLoss: 0.034189\n",
            "Train Epoch: 5 [60000/80000 (75%)]\tLoss: 0.034049\n",
            "Finish\n",
            "Train Epoch: 6 [0/80000 (0%)]\tLoss: 0.031764\n",
            "Train Epoch: 6 [20000/80000 (25%)]\tLoss: 0.033062\n",
            "Train Epoch: 6 [40000/80000 (50%)]\tLoss: 0.028871\n",
            "Train Epoch: 6 [60000/80000 (75%)]\tLoss: 0.029169\n",
            "Finish\n",
            "Train Epoch: 7 [0/80000 (0%)]\tLoss: 0.027203\n",
            "Train Epoch: 7 [20000/80000 (25%)]\tLoss: 0.026562\n",
            "Train Epoch: 7 [40000/80000 (50%)]\tLoss: 0.024772\n",
            "Train Epoch: 7 [60000/80000 (75%)]\tLoss: 0.025126\n",
            "Finish\n",
            "Train Epoch: 8 [0/80000 (0%)]\tLoss: 0.022438\n",
            "Train Epoch: 8 [20000/80000 (25%)]\tLoss: 0.023821\n",
            "Train Epoch: 8 [40000/80000 (50%)]\tLoss: 0.022501\n",
            "Train Epoch: 8 [60000/80000 (75%)]\tLoss: 0.021581\n",
            "Finish\n",
            "Train Epoch: 9 [0/80000 (0%)]\tLoss: 0.022123\n",
            "Train Epoch: 9 [20000/80000 (25%)]\tLoss: 0.020540\n",
            "Train Epoch: 9 [40000/80000 (50%)]\tLoss: 0.022063\n",
            "Train Epoch: 9 [60000/80000 (75%)]\tLoss: 0.020658\n",
            "Finish\n",
            "Train Epoch: 10 [0/80000 (0%)]\tLoss: 0.019879\n",
            "Train Epoch: 10 [20000/80000 (25%)]\tLoss: 0.019618\n",
            "Train Epoch: 10 [40000/80000 (50%)]\tLoss: 0.018993\n",
            "Train Epoch: 10 [60000/80000 (75%)]\tLoss: 0.019212\n",
            "Finish\n",
            "Train Epoch: 11 [0/80000 (0%)]\tLoss: 0.018929\n",
            "Train Epoch: 11 [20000/80000 (25%)]\tLoss: 0.018933\n",
            "Train Epoch: 11 [40000/80000 (50%)]\tLoss: 0.017677\n",
            "Train Epoch: 11 [60000/80000 (75%)]\tLoss: 0.018478\n",
            "Finish\n",
            "Train Epoch: 12 [0/80000 (0%)]\tLoss: 0.015709\n",
            "Train Epoch: 12 [20000/80000 (25%)]\tLoss: 0.015218\n",
            "Train Epoch: 12 [40000/80000 (50%)]\tLoss: 0.016383\n",
            "Train Epoch: 12 [60000/80000 (75%)]\tLoss: 0.014625\n",
            "Finish\n",
            "Train Epoch: 13 [0/80000 (0%)]\tLoss: 0.014699\n",
            "Train Epoch: 13 [20000/80000 (25%)]\tLoss: 0.015749\n",
            "Train Epoch: 13 [40000/80000 (50%)]\tLoss: 0.015230\n",
            "Train Epoch: 13 [60000/80000 (75%)]\tLoss: 0.014909\n",
            "Finish\n",
            "Train Epoch: 14 [0/80000 (0%)]\tLoss: 0.014415\n",
            "Train Epoch: 14 [20000/80000 (25%)]\tLoss: 0.012424\n",
            "Train Epoch: 14 [40000/80000 (50%)]\tLoss: 0.013851\n",
            "Train Epoch: 14 [60000/80000 (75%)]\tLoss: 0.013036\n",
            "Finish\n",
            "Train Epoch: 15 [0/80000 (0%)]\tLoss: 0.012655\n",
            "Train Epoch: 15 [20000/80000 (25%)]\tLoss: 0.013526\n",
            "Train Epoch: 15 [40000/80000 (50%)]\tLoss: 0.013097\n",
            "Train Epoch: 15 [60000/80000 (75%)]\tLoss: 0.012224\n",
            "Finish\n",
            "Train Epoch: 16 [0/80000 (0%)]\tLoss: 0.013744\n",
            "Train Epoch: 16 [20000/80000 (25%)]\tLoss: 0.012207\n",
            "Train Epoch: 16 [40000/80000 (50%)]\tLoss: 0.011181\n",
            "Train Epoch: 16 [60000/80000 (75%)]\tLoss: 0.012919\n",
            "Finish\n",
            "Train Epoch: 17 [0/80000 (0%)]\tLoss: 0.010845\n",
            "Train Epoch: 17 [20000/80000 (25%)]\tLoss: 0.011990\n",
            "Train Epoch: 17 [40000/80000 (50%)]\tLoss: 0.013919\n",
            "Train Epoch: 17 [60000/80000 (75%)]\tLoss: 0.014082\n",
            "Finish\n",
            "Train Epoch: 18 [0/80000 (0%)]\tLoss: 0.011554\n",
            "Train Epoch: 18 [20000/80000 (25%)]\tLoss: 0.009095\n",
            "Train Epoch: 18 [40000/80000 (50%)]\tLoss: 0.011522\n",
            "Train Epoch: 18 [60000/80000 (75%)]\tLoss: 0.010127\n",
            "Finish\n",
            "Train Epoch: 19 [0/80000 (0%)]\tLoss: 0.011561\n",
            "Train Epoch: 19 [20000/80000 (25%)]\tLoss: 0.012376\n",
            "Train Epoch: 19 [40000/80000 (50%)]\tLoss: 0.011452\n",
            "Train Epoch: 19 [60000/80000 (75%)]\tLoss: 0.010025\n",
            "Finish\n",
            "Train Epoch: 20 [0/80000 (0%)]\tLoss: 0.010938\n",
            "Train Epoch: 20 [20000/80000 (25%)]\tLoss: 0.009906\n",
            "Train Epoch: 20 [40000/80000 (50%)]\tLoss: 0.009886\n",
            "Train Epoch: 20 [60000/80000 (75%)]\tLoss: 0.010858\n",
            "Finish\n",
            "Train Epoch: 21 [0/80000 (0%)]\tLoss: 0.009920\n",
            "Train Epoch: 21 [20000/80000 (25%)]\tLoss: 0.009757\n",
            "Train Epoch: 21 [40000/80000 (50%)]\tLoss: 0.009091\n",
            "Train Epoch: 21 [60000/80000 (75%)]\tLoss: 0.008973\n",
            "Finish\n",
            "Train Epoch: 22 [0/80000 (0%)]\tLoss: 0.007166\n",
            "Train Epoch: 22 [20000/80000 (25%)]\tLoss: 0.009634\n",
            "Train Epoch: 22 [40000/80000 (50%)]\tLoss: 0.008317\n",
            "Train Epoch: 22 [60000/80000 (75%)]\tLoss: 0.008183\n",
            "Finish\n",
            "Train Epoch: 23 [0/80000 (0%)]\tLoss: 0.006843\n",
            "Train Epoch: 23 [20000/80000 (25%)]\tLoss: 0.007780\n",
            "Train Epoch: 23 [40000/80000 (50%)]\tLoss: 0.006891\n",
            "Train Epoch: 23 [60000/80000 (75%)]\tLoss: 0.006867\n",
            "Finish\n",
            "Train Epoch: 24 [0/80000 (0%)]\tLoss: 0.008070\n",
            "Train Epoch: 24 [20000/80000 (25%)]\tLoss: 0.007595\n",
            "Train Epoch: 24 [40000/80000 (50%)]\tLoss: 0.006385\n",
            "Train Epoch: 24 [60000/80000 (75%)]\tLoss: 0.006879\n",
            "Finish\n",
            "Train Epoch: 25 [0/80000 (0%)]\tLoss: 0.005533\n",
            "Train Epoch: 25 [20000/80000 (25%)]\tLoss: 0.006104\n",
            "Train Epoch: 25 [40000/80000 (50%)]\tLoss: 0.005831\n",
            "Train Epoch: 25 [60000/80000 (75%)]\tLoss: 0.005896\n",
            "Finish\n",
            "Train Epoch: 26 [0/80000 (0%)]\tLoss: 0.006143\n",
            "Train Epoch: 26 [20000/80000 (25%)]\tLoss: 0.004424\n",
            "Train Epoch: 26 [40000/80000 (50%)]\tLoss: 0.007356\n",
            "Train Epoch: 26 [60000/80000 (75%)]\tLoss: 0.005324\n",
            "Finish\n",
            "Train Epoch: 27 [0/80000 (0%)]\tLoss: 0.004649\n",
            "Train Epoch: 27 [20000/80000 (25%)]\tLoss: 0.007117\n",
            "Train Epoch: 27 [40000/80000 (50%)]\tLoss: 0.006028\n",
            "Train Epoch: 27 [60000/80000 (75%)]\tLoss: 0.006309\n",
            "Finish\n",
            "Train Epoch: 28 [0/80000 (0%)]\tLoss: 0.004910\n",
            "Train Epoch: 28 [20000/80000 (25%)]\tLoss: 0.007181\n",
            "Train Epoch: 28 [40000/80000 (50%)]\tLoss: 0.004431\n",
            "Train Epoch: 28 [60000/80000 (75%)]\tLoss: 0.004815\n",
            "Finish\n",
            "Train Epoch: 29 [0/80000 (0%)]\tLoss: 0.004746\n",
            "Train Epoch: 29 [20000/80000 (25%)]\tLoss: 0.005219\n",
            "Train Epoch: 29 [40000/80000 (50%)]\tLoss: 0.005248\n",
            "Train Epoch: 29 [60000/80000 (75%)]\tLoss: 0.006145\n",
            "Finish\n",
            "Train Epoch: 30 [0/80000 (0%)]\tLoss: 0.005124\n",
            "Train Epoch: 30 [20000/80000 (25%)]\tLoss: 0.005688\n",
            "Train Epoch: 30 [40000/80000 (50%)]\tLoss: 0.006250\n",
            "Train Epoch: 30 [60000/80000 (75%)]\tLoss: 0.005162\n",
            "Finish\n",
            "Train Epoch: 31 [0/80000 (0%)]\tLoss: 0.006061\n",
            "Train Epoch: 31 [20000/80000 (25%)]\tLoss: 0.005544\n",
            "Train Epoch: 31 [40000/80000 (50%)]\tLoss: 0.005355\n",
            "Train Epoch: 31 [60000/80000 (75%)]\tLoss: 0.005427\n",
            "Finish\n",
            "Train Epoch: 32 [0/80000 (0%)]\tLoss: 0.004321\n",
            "Train Epoch: 32 [20000/80000 (25%)]\tLoss: 0.006149\n",
            "Train Epoch: 32 [40000/80000 (50%)]\tLoss: 0.005524\n",
            "Train Epoch: 32 [60000/80000 (75%)]\tLoss: 0.005531\n",
            "Finish\n",
            "Train Epoch: 33 [0/80000 (0%)]\tLoss: 0.004674\n",
            "Train Epoch: 33 [20000/80000 (25%)]\tLoss: 0.004059\n",
            "Train Epoch: 33 [40000/80000 (50%)]\tLoss: 0.005194\n",
            "Train Epoch: 33 [60000/80000 (75%)]\tLoss: 0.005022\n",
            "Finish\n",
            "Train Epoch: 34 [0/80000 (0%)]\tLoss: 0.004460\n",
            "Train Epoch: 34 [20000/80000 (25%)]\tLoss: 0.003874\n",
            "Train Epoch: 34 [40000/80000 (50%)]\tLoss: 0.005251\n",
            "Train Epoch: 34 [60000/80000 (75%)]\tLoss: 0.004482\n",
            "Finish\n",
            "Train Epoch: 35 [0/80000 (0%)]\tLoss: 0.005937\n",
            "Train Epoch: 35 [20000/80000 (25%)]\tLoss: 0.004111\n",
            "Train Epoch: 35 [40000/80000 (50%)]\tLoss: 0.004465\n",
            "Train Epoch: 35 [60000/80000 (75%)]\tLoss: 0.004071\n",
            "Finish\n",
            "Train Epoch: 36 [0/80000 (0%)]\tLoss: 0.005223\n",
            "Train Epoch: 36 [20000/80000 (25%)]\tLoss: 0.005383\n",
            "Train Epoch: 36 [40000/80000 (50%)]\tLoss: 0.003888\n",
            "Train Epoch: 36 [60000/80000 (75%)]\tLoss: 0.004116\n",
            "Finish\n",
            "Train Epoch: 37 [0/80000 (0%)]\tLoss: 0.005474\n",
            "Train Epoch: 37 [20000/80000 (25%)]\tLoss: 0.004254\n",
            "Train Epoch: 37 [40000/80000 (50%)]\tLoss: 0.005094\n",
            "Train Epoch: 37 [60000/80000 (75%)]\tLoss: 0.005569\n",
            "Finish\n",
            "Train Epoch: 38 [0/80000 (0%)]\tLoss: 0.007256\n",
            "Train Epoch: 38 [20000/80000 (25%)]\tLoss: 0.005172\n",
            "Train Epoch: 38 [40000/80000 (50%)]\tLoss: 0.004879\n",
            "Train Epoch: 38 [60000/80000 (75%)]\tLoss: 0.005246\n",
            "Finish\n",
            "Train Epoch: 39 [0/80000 (0%)]\tLoss: 0.005528\n",
            "Train Epoch: 39 [20000/80000 (25%)]\tLoss: 0.005334\n",
            "Train Epoch: 39 [40000/80000 (50%)]\tLoss: 0.005018\n",
            "Train Epoch: 39 [60000/80000 (75%)]\tLoss: 0.005113\n",
            "Finish\n",
            "Train Epoch: 40 [0/80000 (0%)]\tLoss: 0.005591\n",
            "Train Epoch: 40 [20000/80000 (25%)]\tLoss: 0.004316\n",
            "Train Epoch: 40 [40000/80000 (50%)]\tLoss: 0.004600\n",
            "Train Epoch: 40 [60000/80000 (75%)]\tLoss: 0.004359\n",
            "Finish\n",
            "Train Epoch: 41 [0/80000 (0%)]\tLoss: 0.004661\n",
            "Train Epoch: 41 [20000/80000 (25%)]\tLoss: 0.005532\n",
            "Train Epoch: 41 [40000/80000 (50%)]\tLoss: 0.004402\n",
            "Train Epoch: 41 [60000/80000 (75%)]\tLoss: 0.003441\n",
            "Finish\n",
            "Train Epoch: 42 [0/80000 (0%)]\tLoss: 0.006277\n",
            "Train Epoch: 42 [20000/80000 (25%)]\tLoss: 0.004241\n",
            "Train Epoch: 42 [40000/80000 (50%)]\tLoss: 0.003806\n",
            "Train Epoch: 42 [60000/80000 (75%)]\tLoss: 0.005369\n",
            "Finish\n",
            "Train Epoch: 43 [0/80000 (0%)]\tLoss: 0.005141\n",
            "Train Epoch: 43 [20000/80000 (25%)]\tLoss: 0.002660\n",
            "Train Epoch: 43 [40000/80000 (50%)]\tLoss: 0.004480\n",
            "Train Epoch: 43 [60000/80000 (75%)]\tLoss: 0.004296\n",
            "Finish\n",
            "Train Epoch: 44 [0/80000 (0%)]\tLoss: 0.003759\n",
            "Train Epoch: 44 [20000/80000 (25%)]\tLoss: 0.004281\n",
            "Train Epoch: 44 [40000/80000 (50%)]\tLoss: 0.004499\n",
            "Train Epoch: 44 [60000/80000 (75%)]\tLoss: 0.003842\n",
            "Finish\n",
            "Train Epoch: 45 [0/80000 (0%)]\tLoss: 0.004114\n",
            "Train Epoch: 45 [20000/80000 (25%)]\tLoss: 0.002877\n",
            "Train Epoch: 45 [40000/80000 (50%)]\tLoss: 0.003544\n",
            "Train Epoch: 45 [60000/80000 (75%)]\tLoss: 0.003608\n",
            "Finish\n",
            "Train Epoch: 46 [0/80000 (0%)]\tLoss: 0.004886\n",
            "Train Epoch: 46 [20000/80000 (25%)]\tLoss: 0.003423\n",
            "Train Epoch: 46 [40000/80000 (50%)]\tLoss: 0.006239\n",
            "Train Epoch: 46 [60000/80000 (75%)]\tLoss: 0.004732\n",
            "Finish\n",
            "Train Epoch: 47 [0/80000 (0%)]\tLoss: 0.004679\n",
            "Train Epoch: 47 [20000/80000 (25%)]\tLoss: 0.004737\n",
            "Train Epoch: 47 [40000/80000 (50%)]\tLoss: 0.003781\n",
            "Train Epoch: 47 [60000/80000 (75%)]\tLoss: 0.003712\n",
            "Finish\n",
            "Train Epoch: 48 [0/80000 (0%)]\tLoss: 0.003597\n",
            "Train Epoch: 48 [20000/80000 (25%)]\tLoss: 0.003902\n",
            "Train Epoch: 48 [40000/80000 (50%)]\tLoss: 0.003734\n",
            "Train Epoch: 48 [60000/80000 (75%)]\tLoss: 0.003094\n",
            "Finish\n",
            "Train Epoch: 49 [0/80000 (0%)]\tLoss: 0.003296\n",
            "Train Epoch: 49 [20000/80000 (25%)]\tLoss: 0.003633\n",
            "Train Epoch: 49 [40000/80000 (50%)]\tLoss: 0.004368\n",
            "Train Epoch: 49 [60000/80000 (75%)]\tLoss: 0.002208\n",
            "Finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EWtgw4yaqU9Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 逆Feature Engineering"
      ]
    },
    {
      "metadata": {
        "id": "hXhzN39mWP4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def backtoNum(data,preprocess = True):\n",
        "  p = ''\n",
        "  if preprocess:\n",
        "    data = np.array(data)\n",
        "    if len(data)==48:\n",
        "      data = data.reshape(4,12)\n",
        "    elif len(data)==96:\n",
        "      data = data.reshape(8,12)\n",
        "    data = data.tolist()\n",
        "    \n",
        "  for i in range(len(data)):\n",
        "    k = data[i].index(max(data[i]))\n",
        "    if k == 0:\n",
        "      a = ' '\n",
        "    elif k == 1:\n",
        "      a = '+'\n",
        "    else:\n",
        "      a = format(k-2)\n",
        "    p = p+a\n",
        "  return(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MnQwVur_qe8f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 測試結果"
      ]
    },
    {
      "metadata": {
        "id": "jo1D-_p6_X5W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  model.eval()\n",
        "  correct = False\n",
        "  c = 0\n",
        "  for step, (x, y) in enumerate(test_dataloader):\n",
        "    data = x.type(torch.cuda.FloatTensor)\n",
        "    target = y.type(torch.cuda.FloatTensor)\n",
        "\n",
        "    output = model(data)\n",
        "    #print(output)\n",
        "\n",
        "\n",
        "    da = backtoNum(data[0].cpu().detach().numpy())\n",
        "    an = backtoNum(output[0].cpu().detach().numpy())\n",
        "    co = backtoNum(target[0].cpu().detach().numpy())\n",
        "\n",
        "    if an==co:\n",
        "      correct = True\n",
        "      c = c +1\n",
        "    else:\n",
        "      correct = False\n",
        "\n",
        "    if step<20:\n",
        "      print(da+\" ?= \"+an+' '+format(correct)+' '+co)\n",
        "      \n",
        "  p = c*100/len(test_dataloader)\n",
        "  print(\"Accuracy : \"+format(c)+'/'+format(len(test_dataloader))+' = '+format(p)+'%')\n",
        "  print(\"Finish\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XzcuVbx0usYx",
        "colab_type": "code",
        "outputId": "28c92045-7a67-4e52-c18a-b10db467298e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "520+921  ?= 1441 True 1441\n",
            "322+869  ?= 1191 True 1191\n",
            "770+681  ?= 1451 True 1451\n",
            "467+527  ?= 993  False 994 \n",
            "755+556  ?= 1311 True 1311\n",
            "478+442  ?= 920  True 920 \n",
            "536+567  ?= 1103 True 1103\n",
            "591+322  ?= 913  True 913 \n",
            "31+978   ?= 1009 True 1009\n",
            "922+823  ?= 1745 True 1745\n",
            "919+509  ?= 1428 True 1428\n",
            "625+625  ?= 1250 True 1250\n",
            "916+407  ?= 1323 True 1323\n",
            "151+960  ?= 1111 True 1111\n",
            "215+789  ?= 1004 True 1004\n",
            "886+330  ?= 1216 True 1216\n",
            "14+515   ?= 529  True 529 \n",
            "897+290  ?= 1187 True 1187\n",
            "782+361  ?= 1143 True 1143\n",
            "686+362  ?= 1048 True 1048\n",
            "Accuracy : 17264/20000 = 86.32%\n",
            "Finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M-ZPgAjzqmMi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}